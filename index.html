<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Siddarth Mamidanna</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
</head>
<body>
    <div class="container">
        <!-- Hero Section -->
        <section class="hero">
            <div class="hero-content">
                <div class="profile-section">
                    <img src="profile-image.png" alt="Siddarth Mamidanna" class="profile-image">
                    <div class="profile-info">
                        <h1 class="name">Siddarth Mamidanna</h1>
                        <p class="title">Computer Science Undergraduate</p>
                        <p class="affiliation">University of California, Santa Cruz</p>
                        <div class="contact-links">
                            <a href="mailto:spmamida@ucsc.edu" class="contact-link">Email</a>
                            <a href="#" class="contact-link">CV</a>
                            <a href="#" class="contact-link">Google Scholar</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- About Section -->
        <section class="about">
            <div class="section-content">
                <p class="intro">
                    I'm a Computer Science undergraduate student at UC Santa Cruz researching LLM interpretability and explainability with 
                    <a href="#">Prof. Leilani Gilpin</a> and <a href="#">Yilun Zhou</a>. I'm applying to PhD programs in CS this fall (2025), 
                    focusing on interpretability and safety of LLMs.
                </p>
            </div>
        </section>

        <!-- Research Section -->
        <section class="research">
            <div class="section-content">
                <h2 class="section-title">Research</h2>
                <div class="research-content">
                    <p>
                        My primary research focus is in LLM interpretability, specifically mechanistic interpretability. 
                        I believe that interpretability will be crucial to both understanding and improving LLMs, and I'm 
                        particularly interested in applying developing interpretability techniques to real-world applications.
                    </p>
                    <p>
                        I began my research journey in Prof. Gilpin's lab (AIEA), where I co-first authored a paper on LLM 
                        explainability that has accumulated over 100 citations. I then collaborated with Yilun Zhou and 
                        Prof. Ziyu Yao on mechanistic interpretability research, resulting in a paper accepted to EMNLP 2025. 
                        I've also explored broader LLM applications through work with Prof. Ben Nye and Joel Walsh at the USC 
                        Institute for Creative Technologies, focusing on fine-tuning vs. few-shot approaches for automated grading.
                    </p>
                </div>
            </div>
        </section>

        <!-- Publications Section -->
        <section class="publications">
            <div class="section-content">
                <h2 class="section-title">Publications</h2>
                <div class="publications-list">
                    <div class="publication-item">
                        <h3 class="paper-title">Can LLMs Explain Themselves? A Study of LLM-Generated Self-Explanations</h3>
                        <p class="paper-authors">Siddarth Mamidanna, Leilani Gilpin</p>
                        <p class="paper-venue"><em>ArXiv</em>, 2023</p>
                        <div class="paper-links">
                            <a href="https://arxiv.org/abs/2310.11207" class="paper-link">PDF</a>
                        </div>
                    </div>
                    
                    <div class="publication-item">
                        <h3 class="paper-title">All for one: A mechanistic study of how all-shot learning emerges in GPT-2</h3>
                        <p class="paper-authors">Yilun Zhou, Siddarth Mamidanna, Ziyu Yao</p>
                        <p class="paper-venue"><em>EMNLP</em>, 2025</p>
                    </div>
                    
                    <div class="publication-item">
                        <h3 class="paper-title">A Comparison of Fine-Tuning and Few-Shot Approaches for AI-based Short Answer Grading</h3>
                        <p class="paper-authors">Joel Walsh, Siddarth Mamidanna, Benjamin Nye</p>
                        <p class="paper-venue"><em>AIED Workshop</em>, 2025</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Contact Section -->
        <section class="contact">
            <div class="section-content">
                <p class="contact-text">
                    If you're interested in my work, would like to collaborate, or just want to chat, 
                    please feel free to reach out.
                </p>
            </div>
        </section>
    </div>

    <footer>
        <div class="footer-content">
            <p>&copy; 2024 Siddarth Mamidanna</p>
        </div>
    </footer>
</body>
</html> 